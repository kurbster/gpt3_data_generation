defaults:
  - outputs
  - preprocessing_config: record
  - metric: record_f1_score
  - _self_
hydra:
  env:
    model_name: "bert-base-cased"
    dataset_name: "record"
    save_name: "${hydra:env.dataset_name}_${hydra:env.model_name}"

do_train: True
do_eval: True
do_predict: True

model_name: "${hydra:env.model_name}"

# This is used by run_experiment.py file to run a singular experiment
train_file: "datasets/${hydra:env.dataset_name}/generated/gpt3_generated.json"
# This is used by main.py to run multiple experiments
train_files:
  - "datasets/${hydra:env.dataset_name}/generated/gpt3_generated.json"
dataset_name: "${hydra:env.dataset_name}"

cache_dir: ".cache"
output_dir: "models/${hydra:env.dataset_name}/${hydra:env.model_name}"

text_column: "text"
label_column: "label"

save_strategy: "epoch"
evaluation_strategy: "epoch"

num_samples: 1228
batch_tokenization: True

save_total_limit: 1          # Save a max of 1 epoch
preprocessing_num_workers: 4
num_labels: 2

#metric_for_best_model: "accuracy"
# Use our "raw_accuracy" for record
metric_for_best_model: "raw_accuracy"
load_best_model_at_end: True # Load the best model at the end of training

seed: 42
per_device_eval_batch_size: 128
per_device_train_batch_size: 8
max_source_length: 512

# Keep the eval set small to save time
max_eval_samples: 1000

# Set to true if on a TPU
#pad_to_max_length: True

warmup_ratio: .05 # This would match the 11 epochs in eariler experiments
learning_rate: .00002
num_train_epochs: 200
optim: "adamw_torch"

early_stopping_patience: 100
early_stopping_threshold: 0.0001
